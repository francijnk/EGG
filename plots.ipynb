{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fname(fname):\n",
    "    fname = fname[:fname.index('-')]\n",
    "    fname_split = fname.split('_')\n",
    "\n",
    "    channel = fname_split[0]\n",
    "    error_prob = float(fname_split[1]) if not len(fname_split) == 3 else 0.\n",
    "    max_len = int(fname_split[-2])\n",
    "    seed = int(fname_split[-1])\n",
    "\n",
    "    return channel, error_prob, max_len, seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(input_dir):\n",
    "\n",
    "    history_train = defaultdict(list)\n",
    "    history_val = defaultdict(list)\n",
    "    results = defaultdict(lambda: defaultdict(list))\n",
    "    channels = []\n",
    "\n",
    "    for fname in os.listdir(path=input_dir):\n",
    "        \n",
    "        fpath = os.path.join(input_dir, fname)\n",
    "        if fname.endswith('csv'):\n",
    "            channel, error_prob, max_len, seed = parse_fname(fname)\n",
    "            df = pd.read_csv(fpath)\n",
    "\n",
    "            df_train = df[df.phase == 'train']\n",
    "            if error_prob != 0.:\n",
    "                df_noise = df[df.phase == 'val']\n",
    "                df_no_noise = df[df.phase == 'val (nn)']\n",
    "            else:\n",
    "                df_noise = df[df.phase == 'val']\n",
    "                df_no_noise = df[df.phase == 'val']\n",
    "\n",
    "            df_noise = df_noise.assign(noise=['noise' for _ in range(len(df_noise))])\n",
    "            df_noise = df_noise.reset_index(drop=True)\n",
    "            df_noise['accuracy'] = df_noise['accuracy'] / 100\n",
    "\n",
    "            df_no_noise = df_no_noise.assign(noise=['no noise' for _ in range(len(df_noise))])\n",
    "            df_no_noise = df_no_noise.reset_index(drop=True)\n",
    "            df_no_noise['accuracy'] = df_no_noise['accuracy'] / 100\n",
    "\n",
    "            history_val[(max_len, channel, error_prob)].append(df_noise)\n",
    "            history_val[(max_len, channel, error_prob)].append(df_no_noise)\n",
    "            history_train[(max_len, channel, error_prob)].append(df_train)\n",
    "\n",
    "        elif fname.endswith('json'):\n",
    "            channel, error_prob, max_len, seed = parse_fname(fname)\n",
    "            channels.append(channel)\n",
    "            with open(fpath) as file:\n",
    "                fdata = json.load(file)\n",
    "\n",
    "            for dataset_key in ('train', 'test'):\n",
    "                for condition_key in fdata[dataset_key]['evaluation']:\n",
    "                    results[dataset_key]['max_len'].append(max_len)\n",
    "                    results[dataset_key]['channel'].append(channel)\n",
    "                    results[dataset_key]['error_prob'].append(error_prob)\n",
    "                    results[dataset_key]['noise'].append(condition_key)\n",
    "                    measures = fdata[dataset_key]['evaluation'][condition_key]\n",
    "                    for key, val in measures.items():\n",
    "                        results[dataset_key][key].append(val)\n",
    "\n",
    "    channels = set(channels) - {'baseline'}\n",
    "\n",
    "    # history val: export to DataFrame and handle baseline results\n",
    "    for max_len, channel, error_prob in list(history_val.keys()):\n",
    "        if channel != 'baseline':\n",
    "            continue\n",
    "        key = (max_len, channel, error_prob)\n",
    "        for c in channels:\n",
    "            new_key = (max_len, c, error_prob)\n",
    "            history_val[new_key] = history_val[key]\n",
    "            history_train[new_key] = history_train[key]\n",
    "        del history_val[key]\n",
    "        del history_train[key]\n",
    "\n",
    "    for max_len, channel, error_prob in history_val:\n",
    "        for df in history_val[(max_len, channel, error_prob)]:\n",
    "            df['max_len'] = max_len\n",
    "            df['channel'] = channel\n",
    "            df['error_prob'] = error_prob\n",
    "\n",
    "    for max_len, channel, error_prob in history_train:\n",
    "        for df in history_train[(max_len, channel, error_prob)]:\n",
    "            df['max_len'] = max_len\n",
    "            df['channel'] = channel\n",
    "            df['error_prob'] = error_prob\n",
    "\n",
    "    history_val = pd.concat(\n",
    "        [df for key in history_val for df in history_val[key]],\n",
    "        ignore_index=True\n",
    "    )\n",
    "    history_train = pd.concat(\n",
    "        [df for key in history_train for df in history_train[key]],\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "    # results: export to DataFrame and handle baseline results\n",
    "    result_dfs = {}\n",
    "    for key, dictionary in results.items():\n",
    "        df = pd.DataFrame(dictionary)\n",
    "        result_dfs[key] = df\n",
    "\n",
    "    baseline_df_list = []\n",
    "    for dataset_key in result_dfs:\n",
    "        for channel in channels:\n",
    "            for noise_key in result_dfs[dataset_key]['noise'].unique():\n",
    "                if noise_key == 'baseline':\n",
    "                    continue\n",
    "                df = result_dfs[dataset_key].copy(deep=True)\n",
    "                df = df[df['channel'] == 'baseline'].copy(deep=True)\n",
    "                df['channel'] = channel\n",
    "                df['noise'] = noise_key\n",
    "                baseline_df_list.append(df)\n",
    "        baseline_df = pd.concat(baseline_df_list, ignore_index=True)\n",
    "\n",
    "        _results = result_dfs[dataset_key]\n",
    "        _results = _results.drop(_results[_results['channel'] == 'baseline'].index, axis=0)\n",
    "        _results = pd.concat([baseline_df, _results], ignore_index=True)\n",
    "        result_dfs[dataset_key] = _results\n",
    "\n",
    "    print('df columns:', list(result_dfs['test'].columns))\n",
    "    print(\n",
    "        '% empty messages:',\n",
    "        100 * result_dfs['test']['KLD_test_train'].isna().sum() / len(result_dfs['test']),\n",
    "        100 * result_dfs['train']['KLD_test_train'].isna().sum() / len(result_dfs['train']),\n",
    "    )\n",
    "\n",
    "    return history_train, history_val, result_dfs['train'], result_dfs['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_long_data(history_val, metrics, dataset):\n",
    "    data_long = pd.melt(\n",
    "        history_val[history_val.dataset == dataset],\n",
    "        id_vars='epoch max_len channel error_prob noise'.split(),\n",
    "        value_vars=metrics, var_name='metric', value_name='value', ignore_index=True)\n",
    "    # data_long.dropna(inplace=True)\n",
    "    return data_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_plot(plot):\n",
    "    plt.close()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_perchannel(data, out_dir, y_ranges, y_ticks, savename, big):\n",
    "\n",
    "    long = pd.melt(pd.DataFrame(data),\n",
    "        id_vars='max_len channel error_prob noise'.split(),\n",
    "        value_vars=None, var_name='metric', value_name='value', ignore_index=True)\n",
    "    long = long.sort_values('max_len')\n",
    "    long.max_len = long.max_len.astype(str)\n",
    "    long.value = long.value.astype(float)\n",
    "    long.error_prob = long.error_prob.astype(float)\n",
    "\n",
    "    channels = pd.unique(long['channel'])\n",
    "\n",
    "    if big:\n",
    "        savename = f\"all_{savename}\"\n",
    "    else:\n",
    "        long = long[(long['max_len'] == '2') | (long['max_len'] == '4')]\n",
    "    col_names = ['accuracy', 'accuracy_symbol_removal', 'redundancy', 'topsim']\n",
    "    df_metrics = long[long.metric.isin(col_names)]\n",
    "\n",
    "    for channel in channels:\n",
    "        save_as = f\"{savename}_{channel}\"\n",
    "\n",
    "        df = df_metrics.loc[\n",
    "                (df_metrics.channel == channel)]\n",
    "        value_x_tick = [0, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30]\n",
    "        sns.set_style(\"whitegrid\")\n",
    "\n",
    "        if channel == 'symmetric':\n",
    "            with sns.plotting_context(rc={\"legend.fontsize\":20}):\n",
    "                plot = sns.relplot(df, x = \"error_prob\", y= 'value', row=\"metric\", row_order=col_names,\n",
    "                                col=\"max_len\", hue=\"max_len\", style=\"noise\", style_order=[\"noise\", \"no noise\"], kind='line',\n",
    "                                marker ='o', markersize=8, legend=\"brief\", facet_kws={\"margin_titles\": True, 'sharey': False})\n",
    "        else:\n",
    "            plot = sns.relplot(df, x = \"error_prob\", y= 'value', row=\"metric\", row_order=col_names,\n",
    "                            col=\"max_len\", hue=\"max_len\", style=\"noise\", style_order=[\"noise\", \"no noise\"], kind='line',\n",
    "                            marker ='o', markersize=8, legend=False, facet_kws={\"margin_titles\": True, 'sharey': False})\n",
    "\n",
    "        for i, metric in enumerate(col_names):\n",
    "            for ax in plot.axes[i]:  # Each row contains multiple columns\n",
    "                ax.set_ylim(*y_ranges.get(metric, (0, 1)))  # Set y-axis range\n",
    "                ax.set_yticks(y_ticks.get(metric, [0, 0.2, 0.4, 0.6, 0.8, 1.0]))  # Set y-ticks\n",
    "                ax.set_yticklabels(y_ticks.get(metric, [0, 0.2, 0.4, 0.6, 0.8, 1.0]), size = '25')       \n",
    "        \n",
    "        for ax in plot.axes.flatten():\n",
    "            ax.tick_params(labelbottom=True)\n",
    "\n",
    "        plot.set(xticks=value_x_tick)\n",
    "        (plot\n",
    "        .set_axis_labels(\"Error Probability\", \"Value\", size = '25')\n",
    "        .set_titles(col_template=\"max len {col_name}\", row_template=\"{row_name}\", size = '25')\n",
    "        .set_xticklabels(value_x_tick, size = '20')\n",
    "        .tight_layout())\n",
    "        plot.fig.subplots_adjust(top=0.94)\n",
    "        plot.fig.suptitle(f'{channel}', fontsize = '30')\n",
    "        #plot.savefig(os.path.join(out_dir, save_as))\n",
    "        plot.savefig(\n",
    "            os.path.join(out_dir, f\"{save_as}.pdf\"),\n",
    "            format='pdf',\n",
    "            dpi=None,\n",
    "            pad_inches=0.01,\n",
    "            bbox_inches='tight',\n",
    "        )\n",
    "        close_plot(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"ancm/runs/03_05/visa/\"\n",
    "output_folder = \"ancm/results/03_05/visa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df columns: ['max_len', 'channel', 'error_prob', 'noise', 'samples', 'samples_per_target_obj', 'samples_per_cat', 'unique_msg', 'unique_samples', 'unique_target_objs', 'unique_target_objs_per_msg', 'unique_samples_per_target_obj', 'unique_samples_cat', 'unique_cat', 'unique_samples_per_target_cat', 'unique_cats_per_msg', 'average_length', 'actual_vocab_size', 'accuracy', 'accuracy_symbol_removal', 'max_rep', 'redundancy', 'topsim', 'entropy_msg', 'entropy_msg_as_a_whole', 'entropy_max', 'entropy_min', 'entropy_min_cat', 'entropy_input', 'mutual_info_msg_input', 'variation_of_info_msg_input', 'proficiency_msg_input', 'redundancy_msg_input', 'entropy_category', 'mutual_info_msg_category', 'variation_of_info_msg_category', 'proficiency_msg_category', 'redundancy_msg_category', 'KLD_train_test', 'KLD_test_train']\n",
      "% empty messages: 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "processed_data_path = os.path.join(input_folder, 'processed')\n",
    "\n",
    "visa_history_train, visa_history_test, visa_results_train, visa_results_test = load_data(input_folder)\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ranges = {\n",
    "    \"accuracy\": (0.4, 0.9),\n",
    "    \"accuracy_symbol_removal\": (0.3, 0.8),\n",
    "    \"redundancy\": (0.0, 0.4),\n",
    "    \"topsim\": (0.1, 0.4),\n",
    "    }\n",
    "\n",
    "y_ticks = {\n",
    "    \"accuracy\": [0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "    \"accuracy_symbol_removal\": [0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
    "    \"redundancy\": [0.0, 0.1, 0.2, 0.3, 0.4],\n",
    "    \"topsim\": [0.1, 0.2, 0.3, 0.4],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_perchannel(visa_results_test, output_folder, y_ranges, y_ticks, savename=\"visa_test\", big=True)\n",
    "plot_perchannel(visa_results_test, output_folder, y_ranges, y_ticks, savename=\"visa_test\", big=False)\n",
    "#plot_perchannel(visa_results_train, output_folder, y_ranges, y_ticks, savename=\"visa_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder_obv = \"ancm/runs/03_05/obverter_10/\"\n",
    "output_folder_obv = \"ancm/results/03_05/obverter_10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df columns: ['max_len', 'channel', 'error_prob', 'noise', 'samples', 'samples_per_target_obj', 'unique_msg', 'unique_samples', 'unique_target_objs', 'unique_target_objs_per_msg', 'unique_samples_per_target_obj', 'average_length', 'actual_vocab_size', 'accuracy', 'accuracy_symbol_removal', 'max_rep', 'redundancy', 'topsim', 'entropy_msg', 'entropy_msg_as_a_whole', 'entropy_max', 'entropy_min', 'entropy_attr', 'entropy_shape', 'mutual_info_msg_shape', 'variation_of_info_msg_shape', 'proficiency_msg_shape', 'redundancy_msg_shape', 'entropy_color', 'mutual_info_msg_color', 'variation_of_info_msg_color', 'proficiency_msg_color', 'redundancy_msg_color', 'entropy_xpos', 'mutual_info_msg_xpos', 'variation_of_info_msg_xpos', 'proficiency_msg_xpos', 'redundancy_msg_xpos', 'entropy_ypos', 'mutual_info_msg_ypos', 'variation_of_info_msg_ypos', 'proficiency_msg_ypos', 'redundancy_msg_ypos', 'entropy_rotation', 'mutual_info_msg_rotation', 'variation_of_info_msg_rotation', 'proficiency_msg_rotation', 'redundancy_msg_rotation', 'KLD_train_test', 'KLD_test_train']\n",
      "% empty messages: 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "processed_data_path = os.path.join(input_folder_obv, 'processed')\n",
    "\n",
    "obv_history_train, obv_history_test, obv_results_train, obv_results_test = load_data(input_folder_obv)\n",
    "\n",
    "os.makedirs(output_folder_obv, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ranges = {\n",
    "    \"accuracy\": (0.5, 0.9),\n",
    "    \"accuracy_symbol_removal\": (0.3, 0.8),\n",
    "    \"redundancy\": (0.0, 0.6),\n",
    "    \"topsim\": (0, 0.3),\n",
    "    }\n",
    "\n",
    "y_ticks = {\n",
    "    \"accuracy\": [0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "    \"accuracy_symbol_removal\": [0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
    "    \"redundancy\": [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6],\n",
    "    \"topsim\": [0.0, 0.1, 0.2, 0.3],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_perchannel(obv_results_test, output_folder, y_ranges, y_ticks, savename=\"obv_test\", big=True)\n",
    "plot_perchannel(obv_results_test, output_folder, y_ranges, y_ticks, savename=\"obv_test\", big=False)\n",
    "#plot_perchannel(obv_results_train, output_folder, y_ranges, y_ticks, savename=\"obv_train\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
